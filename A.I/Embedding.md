## Embedding(임베딩)이란?

```
자연어처리에서 사람이 쓰는 자연어를  기계가 이해할 수 있도록 숫자형태인 vector로 바꾸는 과정 혹은 일련이 전체 과정을 의미합니다.
``` 

<br>

가장 간단한 형태의 엠베딩은 단어의 빈도를 기준으로 벡터화 하는 것 입니다.


![임베딩](https://github.com/yumalg12/tech-study/assets/74216748/da34fabf-3ca2-476a-9205-0430e9f9f645)


위의 표와 같이 운수좋은 날 이라는 문서의 임베딩은 [2,1,1] 이 됩니다. 또한 막걸리 단어의 인베딩은 [0,1,0,0]이 되며 사랑손님과 어머니, 삼포 가는길에서 사용하는 단어 목록이 상대적으로 많이 겹치는 것을 알 수 있습니다.


임베딩의 역할

-  단어/문장 간 관련도 계산
-  의미적/문법적 정보 함축
-  전이 학습


1. 단어/문장 간 관련도 계산

```
단어-문장 행렬은 가장 단순한 형태의 임베딩입니다. 대표적인 임베딩 기법은 Word2Vec가 있습니다. 전체단어들간의 관계에 맞춰 해당 단어의 특성을 갖는 벡터로 바꾸면 단어들 사이의 유사도를 계산하는 일이 가능해집니다. 
```

유사도

- 희망이라는 단어를 Word2Vec을 활용해서 임베딩하면 
ex) 희망 = [-0.00209, -0.03918, ... 0.01715, -0.04975, 0.09300] 

2. 의미적/문법적 정보 함축

```
단어 벡터 간 덧셈/뺄셈을 통해 단어들 사이의 의미적,문법적 관계를 도출해 낼 수 있습니다.
```

ex) 아들 - 딸 = 소년 = 소녀


3. 전이학습

```
임베딩은 다른 딥러닝 모델이  입력값으로 자주 쓰이고 성능이 좋은 임베딩을 쓸수록 모델의  성능이 좋아집니다.
```

ex) 대규모 말뭉치를 활용해서 임베딩을 미리 만들어 놓고 이 임베딩을 입력값으로 쓰는 전이 학습 모델은 문서 분류같은 일을 빠르게 처리 할 수있습니다.
(임베딩 값이 좋을수록 성능이 올라가고 손실률도 적습니다.)


출처 
<br>
https://velog.io/@glad415/%EC%9E%84%EB%B2%A0%EB%94%A9Embedding%EC%9D%B4%EB%9E%80
https://casa-de-feel.tistory.com/28
